import streamlit as st  # type: ignore

# è®¾ç½® ZhipuAI API Key
st.sidebar.title("è®¾ç½®")

global api_key_option
api_key_option = st.sidebar.radio("é€‰æ‹© API å¯†é’¥é€‰é¡¹ï¼š", ("è¾“å…¥è‡ªå®šä¹‰å¯†é’¥", "ä½¿ç”¨é»˜è®¤å¯†é’¥"))

# Streamlit å‰ç«¯ç•Œé¢
st.title("ğŸ” åŸºäºæœ¬åœ°çŸ¥è¯†åº“çš„é—®ç­”ç³»ç»Ÿ")
st.markdown("æœ¬ç³»ç»Ÿä¸»è¦é€šè¿‡æœ¬åœ°çŸ¥è¯†åº“æ£€ç´¢ç­”æ¡ˆï¼Œå¹¶ç»“åˆ ChatGLM ç”Ÿæˆæ¸…æ™°ã€å‡†ç¡®çš„å›ç­”ã€‚")
st.write("---")  # åˆ†éš”çº¿

# åˆå§‹åŒ– session_state ç”¨äºå­˜å‚¨é—®ç­”å†å²
if "qa_history" not in st.session_state:
    st.session_state["qa_history"] = [{"role": "assistant", "content": "æ‚¨å¥½ï¼è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨ï¼Ÿ"}]

# æ˜¾ç¤ºå¯¹è¯å†å²
for msg in st.session_state["qa_history"]:
    if msg["role"] == "user":
        st.chat_message("user").write(msg["content"])
    else:
        st.chat_message("assistant").write(msg["content"])

# å®šä¹‰æ£€ç´¢å’Œå›ç­”å‡½æ•°
def retrieve_answer(question):
    from langchain_community.embeddings import HuggingFaceBgeEmbeddings  # type: ignore
    from langchain_community.vectorstores import FAISS  # type: ignore
    from zhipuai import ZhipuAI  # type: ignore

    # è·å– API å¯†é’¥
    if api_key_option == "è¾“å…¥è‡ªå®šä¹‰å¯†é’¥":
        zhipu_api_key = st.sidebar.text_input("è¾“å…¥æ‚¨çš„ ZhipuAI API å¯†é’¥", type="password", help="ä» https://open.bigmodel.cn/usercenter/apikeys è·å–å¯†é’¥")
    else:
        zhipu_api_key = "your_key_in_there"  # æ›¿æ¢ä¸ºé»˜è®¤å¯†é’¥

    if not zhipu_api_key:
        st.warning("è¯·è¾“å…¥æ‚¨çš„ ZhipuAI API å¯†é’¥ã€‚")
        st.warning("æ‚¨å¯ä»¥ä» https://open.bigmodel.cn/usercenter/apikeys è·å–å¯†é’¥ã€‚")
        st.stop()
        return

    # åˆå§‹åŒ– ZhipuAI å®¢æˆ·ç«¯
    client = ZhipuAI(api_key=zhipu_api_key)

    # åŠ è½½åµŒå…¥æ¨¡å‹
    model_name = "BAAI/bge-large-zh-v1.5"  # æ›¿æ¢ä¸ºä¸­æ–‡æ¨¡å‹
    model_kwargs = {"device": "cpu"}
    encode_kwargs = {"normalize_embeddings": True}
    bgeEmbeddings = HuggingFaceBgeEmbeddings(
        model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs
    )

    # åŠ è½½æœ¬åœ°å‘é‡æ•°æ®åº“
    db_path = "weibo"  # æ›¿æ¢ä¸ºæœ¬åœ°å‘é‡æ•°æ®åº“è·¯å¾„
    new_db = FAISS.load_local(db_path, bgeEmbeddings, allow_dangerous_deserialization=True)
    docs = new_db.similarity_search(question)

    # æå–ä¸Šä¸‹æ–‡å†…å®¹
    context = "\n\n".join([doc.page_content for doc in docs]) if docs else "æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£å†…å®¹ã€‚"

    # è°ƒè¯•ä¿¡æ¯
    # st.write("æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ï¼š", context)

    # è°ƒç”¨ ZhipuAI çš„ API ç”Ÿæˆå›ç­”
    with st.spinner("æ­£åœ¨æ£€ç´¢ç­”æ¡ˆ..."):
        response = client.chat.completions.create(
            model="glm-4-long",
            messages=[
                {
                    "role": "user",
                    "content": (
                        "è¯·æ ¹æ®æœ¬åœ°çŸ¥è¯†åº“ï¼Œå›ç­”ä»¥ä¸‹é—®é¢˜ï¼Œå¹¶å§‹ç»ˆç”¨ä¸­æ–‡ä½œç­”ã€‚\n\n"
                        "### å›ç­”è§„åˆ™ï¼š\n"
                        "1. ä¼˜å…ˆä½¿ç”¨æœ¬åœ°å¾®åšè¯„è®ºçŸ¥è¯†åº“ä¸­çš„ä¿¡æ¯è¿›è¡Œå›ç­”ã€‚\n"
                        "2. å¦‚æœæœ¬åœ°å¾®åšè¯„è®ºçŸ¥è¯†åº“ä¸­çš„ä¿¡æ¯ä¸è¶³ï¼Œè¯·è¡¥å……ä½¿ç”¨ç½‘ç»œæœç´¢ç»“æœã€‚\n"
                        "3. å¦‚æœæ— æ³•ä»æœ¬åœ°å¾®åšè¯„è®ºçŸ¥è¯†åº“æˆ–ç½‘ç»œæœç´¢ä¸­æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ï¼Œè¯·å›ç­”ï¼šâ€œæ­¤ä¿¡æ¯åœ¨æœ¬åœ°å¾®åšè¯„è®ºçŸ¥è¯†åº“æˆ–ç½‘ç»œæœç´¢ç»“æœä¸­å‡ä¸å¯ç”¨ã€‚â€\n\n"
                        "### æä¾›çš„æœ¬åœ°å¾®åšè¯„è®ºçŸ¥è¯†åº“ï¼š\n"
                        f"\"\"\"\n{context}\n\"\"\"\n\n"
                        "### é—®é¢˜ï¼š\n"
                        f"\"\"\"\n{question}\n\"\"\"\n\n"
                        "### å›ç­”è¦æ±‚ï¼š\n"
                        "1. è¯·ç›´æ¥æä¾›æœ€ç»ˆç­”æ¡ˆã€‚\n"
                        "2. æ˜ç¡®æŒ‡å‡ºç­”æ¡ˆçš„æ¥æºï¼šâ€œå¾®åšè¯„è®ºçŸ¥è¯†åº“â€ã€â€œç½‘ç»œæœç´¢â€æˆ–â€œä¸¤è€…ç»“åˆâ€ã€‚\n"
                        "3. å¦‚æœå›ç­”ä¸­åŒ…å«å¯¹è¯„è®ºå†…å®¹çš„åˆ†ææˆ–è§£é‡Šï¼Œè¯·æä¾›ç®€è¦çš„è¯´æ˜ã€‚\n"
                        "4. ç¡®ä¿å›ç­”å†…å®¹ç®€æ´æ˜äº†ï¼Œç¬¦åˆç½‘ç»œäº¤æµçš„è¡¨è¿°ä¹ æƒ¯ï¼Œé¿å…å†—é•¿ã€‚\n\n"
                        "### è¯·å¼€å§‹å›ç­”ï¼š"
                        "### ä¸¾ä¾‹ï¼š \n"
                        "é—®é¢˜1ï¼š ç”¨æˆ·å¯¹æŸæ˜æ˜Ÿæ–°ç”µå½±çš„è¯„è®ºæ€åº¦å¦‚ä½•ï¼Ÿ\n"
                        "å›ç­”1ï¼šå¤šæ•°ç”¨æˆ·æŒæ­£é¢æ€åº¦ï¼Œè®¤ä¸ºç”µå½±å‰§æƒ…å¸å¼•äººï¼Œæ¼”å‘˜è¡¨ç°åŠ›å¼ºã€‚\n"
                        "é—®é¢˜2ï¼š ç½‘å‹å¯¹æŸå“ç‰Œæ‰‹æœºæœ€æ–°æ¬¾å¼çš„è¯„ä»·æ€æ ·ï¼Ÿ\n"
                        "å›ç­”2ï¼šè¯„ä»·è¤’è´¬ä¸ä¸€ï¼Œéƒ¨åˆ†ç”¨æˆ·è®¤ä¸ºæ–°æ¬¾æ‰‹æœºè®¾è®¡æ–°é¢–ï¼Œæ€§èƒ½æå‡æ˜æ˜¾ï¼Œä½†ä¹Ÿæœ‰ç”¨æˆ·åæ˜ ä»·æ ¼åé«˜ï¼Œæ€§ä»·æ¯”ä¸å¦‚é¢„æœŸã€‚\n"
                    ),
                }
            ],
            stream=True,
        )
        answer = "".join(chunk.choices[0].delta.content for chunk in response)

    # æ£€æŸ¥å›ç­”æ˜¯å¦ä¸ºç©º
    if not answer.strip():
        st.error("API è¿”å›çš„å›ç­”ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ¨¡å‹æˆ–ä¸Šä¸‹æ–‡å†…å®¹æ˜¯å¦æ­£ç¡®ã€‚")
    return answer

# å¤„ç†ç”¨æˆ·è¾“å…¥å’Œå“åº”
if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼š"):
    # ä¿å­˜ç”¨æˆ·è¾“å…¥
    st.session_state["qa_history"].append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    # è·å–å›ç­”å¹¶æ˜¾ç¤ºè¿›åº¦æ¡
    response = retrieve_answer(prompt)
    st.session_state["qa_history"].append({"role": "assistant", "content": response})
    st.chat_message("assistant").write(response)

# æ¸…é™¤èŠå¤©è®°å½•æŒ‰é’®

if st.sidebar.button("æ¸…é™¤èŠå¤©è®°å½•"):
    st.session_state.clear()
    st.session_state["qa_history"] = [{"role": "assistant", "content": "æ‚¨å¥½ï¼è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨ï¼Ÿ"}]